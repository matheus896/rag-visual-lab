"""
RAG Agente - Laborat√≥rio Visual de RAG
======================================

Demonstra√ß√£o de RAG com roteamento de datasets inteligente usando CrewAI.

Este m√≥dulo implementa um chatbot que usa um agente de IA para decidir
qual base vetorial √© mais apropriada para responder uma pergunta. O agente
analisa a query do usu√°rio e roteia para o dataset correto (ex: direito_constitucional
ou synthetic_dataset_papers), depois executa o pipeline RAG completo naquele dataset.

Funcionalidades:
- Chat interativo com roteamento autom√°tico de datasets
- Agente CrewAI que analisa e decide dataset apropriado
- Visualiza√ß√£o do racioc√≠nio do agente (transpar√™ncia did√°tica)
- Pipeline RAG completo (Retrieval + Augmentation + Generation)
- Hist√≥rico de conversa com visualiza√ß√£o dos logs do agente

Arquitetura (Task 4):
1. AgenticRAGProvider ‚Üí Roteia query para dataset correto
2. RetrieverProvider ‚Üí Busca chunks no dataset selecionado
3. AugmentationProvider ‚Üí Enriquece prompt com chunks
4. GeminiProvider ‚Üí Gera resposta final
"""

import streamlit as st
import os
import sys
from typing import Dict, Optional

# Adiciona o diret√≥rio raiz ao path para imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from services.agentic_rag_provider import AgenticRAGProvider
from services.retriever_provider import RetrieverProvider
from services.augmentation_provider import AugmentationProvider
from services.gemini_provider import (
    GeminiConfig,
    get_gemini_llm_function,
    validate_gemini_api_key
)


# ==================== CONFIGURA√á√ÉO DA P√ÅGINA ====================

st.set_page_config(
    page_title="RAG Agente | Lab Visual",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ü§ñ Laborat√≥rio de RAG Agente")
st.markdown("""
Converse com um assistente **inteligente** que roteia automaticamente sua pergunta 
para a base de conhecimento mais apropriada. O agente analisa sua query e decide 
qual dataset usar, tornando o processo **transparente e did√°tico**.
""")

st.divider()


# ==================== INICIALIZA√á√ÉO DO STATE ====================

def initialize_session_state():
    """Inicializa as vari√°veis de estado da sess√£o."""
    if "rag_agentic_messages" not in st.session_state:
        st.session_state.rag_agentic_messages = []
    
    if "rag_agentic_logs" not in st.session_state:
        st.session_state.rag_agentic_logs = ""
    
    if "rag_agentic_provider" not in st.session_state:
        st.session_state.rag_agentic_provider = AgenticRAGProvider()
    
    # Configura√ß√µes padr√£o do ChromaDB
    if "agentic_chroma_db_path" not in st.session_state:
        st.session_state.agentic_chroma_db_path = "./chroma_db"
    
    if "agentic_chroma_n_results" not in st.session_state:
        st.session_state.agentic_chroma_n_results = 10

initialize_session_state()


# ==================== SIDEBAR - CONFIGURA√á√ïES ====================

with st.sidebar:
    st.header("‚öôÔ∏è Configura√ß√µes")
    
    # Valida√ß√£o da API Key do Gemini
    api_key = st.text_input(
        "Gemini API Key",
        type="password",
        value=os.getenv("GEMINI_API_KEY", ""),
        help="Obtenha sua chave em https://ai.google.dev/"
    )
    
    api_key_valid = validate_gemini_api_key(api_key)
    
    if api_key_valid:
        st.success("‚úÖ API Key v√°lida")
    else:
        st.error("‚ùå API Key inv√°lida ou n√£o fornecida")
    
    st.divider()
    
    # Configura√ß√µes do ChromaDB
    st.subheader("üóÑÔ∏è Configura√ß√£o do ChromaDB")
    
    st.session_state.agentic_chroma_db_path = st.text_input(
        "Caminho do Banco",
        value=st.session_state.agentic_chroma_db_path,
        help="Caminho para o diret√≥rio do ChromaDB persistente"
    )
    
    st.session_state.agentic_chroma_n_results = st.slider(
        "N√∫mero de Chunks",
        min_value=1,
        max_value=20,
        value=st.session_state.agentic_chroma_n_results,
        help="Quantidade de chunks a recuperar por consulta"
    )
    
    st.divider()
    
    # Bot√£o para limpar hist√≥rico
    if st.button("üóëÔ∏è Limpar Conversa", use_container_width=True):
        st.session_state.rag_agentic_messages = []
        st.session_state.rag_agentic_logs = ""
        st.success("Conversa limpa com sucesso!")
        st.rerun()
    
    st.divider()
    
    # Informa√ß√µes sobre o Agente
    st.subheader("‚ÑπÔ∏è Sobre o Agente")
    st.info("""
    **CrewAI**: Framework para construir agentes IA colaborativos.
    
    **Roteamento Autom√°tico**: O agente analisa sua query e escolhe:
    - `synthetic_dataset_papers` para perguntas sobre datasets sint√©ticos
    - `direito_constitucional` para perguntas sobre direito
    
    **Transpar√™ncia**: Voc√™ v√™ o racioc√≠nio do agente ao lado.
    """)


# ==================== FUN√á√ÉO AUXILIAR - PIPELINE AGENTE RAG ====================

def build_agentic_rag_pipeline(query: str, api_key: str) -> tuple[str, Dict, str]:
    """
    Pipeline Agentic RAG que roteia queries para datasets apropriados.
    
    Fluxo:
    1. AgenticRAGProvider ‚Üí Roteia query para dataset correto via CrewAI
    2. RetrieverProvider ‚Üí Busca chunks no dataset selecionado
    3. AugmentationProvider ‚Üí Enriquece prompt com chunks
    4. Generation ‚Üí LLM gera resposta final
    
    Args:
        query: Pergunta do usu√°rio
        api_key: Chave da API Gemini
        
    Returns:
        Uma tupla contendo (resposta, routing_result, agent_reasoning)
    """
    agent_reasoning = ""
    routing_result = {}
    
    try:
        # ===== ETAPA 1: AGENTIC ROUTING =====
        print(f"\nü§ñ [AGENTIC ROUTING] Analisando query para rotear dataset...")
        
        # Executar roteamento (os logs j√° v√£o para o terminal via TeeOutput no provider)
        routing_result = st.session_state.rag_agentic_provider.route_query(query)
        
        # Obter logs capturados do provider
        agent_reasoning = st.session_state.rag_agentic_provider.last_logs
        
        if not routing_result:
            return "‚ùå Erro: O agente n√£o conseguiu rotear a query.", {}, agent_reasoning
        
        dataset_name = routing_result.get("dataset_name")
        locale = routing_result.get("locale")
        translated_query = routing_result.get("query", query)
        
        print(f"‚úÖ [AGENTIC ROUTING] Dataset selecionado: {dataset_name}")
        print(f"   ‚îî‚îÄ Locale: {locale}")
        print(f"   ‚îî‚îÄ Query traduzida: {translated_query}")
        
        # ===== ETAPA 2: RETRIEVAL =====
        print(f"\nüîé [RETRIEVAL] Buscando chunks em '{dataset_name}'...")
        
        retriever = RetrieverProvider(
            db_path=st.session_state.agentic_chroma_db_path,
            collection_name=dataset_name
        )
        
        chunks = retriever.search(
            query_text=translated_query,
            n_results=st.session_state.agentic_chroma_n_results
        )
        
        if not chunks:
            st.warning(f"""
            ‚ö†Ô∏è Nenhum chunk recuperado de '{dataset_name}'. 
            Verifique se a cole√ß√£o existe e cont√©m documentos.
            """)
            chunks = [f"Informa√ß√£o padr√£o sobre {dataset_name}"]
        
        print(f"‚úÖ [RETRIEVAL] Encontrados {len(chunks)} chunks")
        
        # ===== ETAPA 3: AUGMENTATION =====
        print(f"\nüìù [AUGMENTATION] Enriquecendo prompt com chunks...")
        
        augmenter = AugmentationProvider(talk_id="agentic_session")
        prompt = augmenter.generate_prompt(query=translated_query, chunks=chunks)
        
        print(f"‚úÖ [AUGMENTATION] Prompt gerado ({len(prompt)} caracteres)")
        
        # ===== ETAPA 4: GENERATION =====
        print(f"\nü§ñ [GENERATION] Gerando resposta com Gemini...")
        
        llm_config = GeminiConfig(api_key=api_key, temperature=0.7, max_tokens=2000)
        llm_function = get_gemini_llm_function(llm_config)
        
        response = llm_function(prompt)
        
        print(f"‚úÖ [GENERATION] Resposta gerada ({len(response)} caracteres)")
        
        return response, routing_result, agent_reasoning
        
    except Exception as e:
        error_msg = str(e)
        print(f"‚ùå Erro no pipeline: {error_msg}")
        
        if "does not exist" in error_msg:
            return f"""
‚ùå **Erro de Configura√ß√£o do ChromaDB**

A cole√ß√£o n√£o foi encontrada no caminho configurado.

**Poss√≠veis solu√ß√µes**:
1. Verifique se o caminho est√° correto
2. Verifique se a cole√ß√£o foi criada
3. Tente usar o caminho absoluto

**Dataset esperado**: {routing_result.get('dataset_name', 'desconhecido')}
**Caminho configurado**: {st.session_state.agentic_chroma_db_path}
            """, routing_result, agent_reasoning
        else:
            return f"‚ùå Erro: {error_msg}", routing_result, agent_reasoning


# ==================== INTERFACE DE CHAT ====================

# Exibe o hist√≥rico de mensagens
if st.session_state.rag_agentic_messages:
    for message in st.session_state.rag_agentic_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
else:
    st.info("üëã Ol√°! Sou um assistente agente de RAG. Qual √© sua d√∫vida?")

# Input de chat
if user_query := st.chat_input("Digite sua pergunta..."):
    # Verifica se a API key √© v√°lida
    if not api_key_valid:
        st.error("‚ö†Ô∏è Por favor, configure uma API Key v√°lida na barra lateral.")
    else:
        # Exibe a mensagem do usu√°rio
        with st.chat_message("user"):
            st.markdown(user_query)
        
        # Adiciona ao hist√≥rico
        st.session_state.rag_agentic_messages.append({
            "role": "user",
            "content": user_query
        })
        
        # Gera a resposta usando o pipeline agentic RAG
        with st.chat_message("assistant"):
            with st.spinner("Analisando e roteando sua pergunta..."):
                response, routing_info, agent_logs = build_agentic_rag_pipeline(
                    query=user_query,
                    api_key=api_key
                )
                
                # Exibe a resposta principal
                st.markdown(response)
                
                # Exibe informa√ß√µes do roteamento
                if routing_info:
                    col1, col2 = st.columns(2)
                    with col1:
                        with st.expander("üìä Informa√ß√µes do Roteamento"):
                            st.json(routing_info)
                    
                    with col2:
                        with st.expander("üß† Racioc√≠nio do Agente"):
                            st.code(agent_logs, language="text")
        
        # Adiciona resposta ao hist√≥rico
        st.session_state.rag_agentic_messages.append({
            "role": "assistant",
            "content": response
        })
        
        # Rerun para atualizar a interface
        st.rerun()


# ==================== FOOTER ====================

st.divider()

with st.expander("üîç Ver Informa√ß√µes T√©cnicas - Pipeline Agentic RAG"):
    st.markdown("""
    ### Arquitetura Agentic RAG
    
    O diferencial desta abordagem √© o **roteamento inteligente**:
    
    #### Componentes
    
    1. **AgenticRAGProvider**: Agent CrewAI que roteia queries
       - Analisa a inten√ß√£o do usu√°rio
       - Consulta lista de datasets dispon√≠veis
       - Seleciona o mais apropriado
       - **Retorna**: `{dataset_name, locale, translated_query}`
    
    2. **RetrieverProvider**: Busca no dataset selecionado
       - Usa embeddings sem√¢nticos
       - Recupera chunks mais relevantes
    
    3. **AugmentationProvider**: Enriquecimento de prompt
       - Combina chunks + contexto
       - Gera prompt otimizado para LLM
    
    4. **GeminiProvider**: Gera√ß√£o de resposta
       - LLM processa prompt enriquecido
       - Retorna resposta contextualizada
    
    #### Fluxo Completo
    
    ```
    Pergunta do Usu√°rio
         ‚Üì
    ü§ñ AgenticRAGProvider.route_query()
         ‚îú‚îÄ Analisa intent da query
         ‚îú‚îÄ Consulta datasets dispon√≠veis
         ‚îî‚îÄ Seleciona dataset correto
         ‚Üì
    üîé RetrieverProvider.search()
         ‚îú‚îÄ Busca em dataset selecionado
         ‚îî‚îÄ Retorna chunks relevantes
         ‚Üì
    üìù AugmentationProvider.generate_prompt()
         ‚îú‚îÄ Combina chunks + contexto
         ‚îî‚îÄ Cria prompt otimizado
         ‚Üì
    ü§ñ GeminiProvider.generate()
         ‚îú‚îÄ LLM processa prompt
         ‚îî‚îÄ Retorna resposta final
         ‚Üì
    Resposta ao Usu√°rio
    ```
    
    #### Vantagens do Roteamento Agente
    
    - ‚úÖ **Intelig√™ncia**: Agent aprende padr√µes de queries
    - ‚úÖ **Escalabilidade**: F√°cil adicionar novos datasets
    - ‚úÖ **Precis√£o**: Dataset certo = respostas mais acuradas
    - ‚úÖ **Transpar√™ncia**: Racioc√≠nio do agente √© vis√≠vel
    - ‚úÖ **Did√°tico**: Perfeito para ensinar RAG avan√ßado
    
    #### Datasets Dispon√≠veis
    
    | Dataset | Locale | Descri√ß√£o |
    |---------|--------|-----------|
    | `synthetic_dataset_papers` | `en` | Sobre datasets sint√©ticos e IA |
    | `direito_constitucional` | `pt-br` | Direito, leis e jurisprud√™ncia |
    
    #### Exemplo de Uso
    
    **Query**: "O que √© abandono afetivo no direito constitucional?"
    
    **Roteamento do Agent**:
    ```json
    {
      "dataset_name": "direito_constitucional",
      "locale": "pt-br",
      "query": "O que √© direito constitucional fala do abandono afetivo?"
    }
    ```
    
    **Pipeline**: Busca em `direito_constitucional` ‚Üí Retorna chunks jur√≠dicos ‚Üí LLM gera resposta especializada
    """)
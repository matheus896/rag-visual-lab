"""
RAG Agente - LaboratÃ³rio Visual de RAG
======================================

DemonstraÃ§Ã£o de RAG com roteamento de datasets inteligente usando CrewAI.

Este mÃ³dulo implementa um chatbot que usa um agente de IA para decidir
qual base vetorial Ã© mais apropriada para responder uma pergunta. O agente
analisa a query do usuÃ¡rio e roteia para o dataset correto (ex: direito_constitucional
ou synthetic_dataset_papers), depois executa o pipeline RAG completo naquele dataset.

Funcionalidades:
- Chat interativo com roteamento automÃ¡tico de datasets
- Agente CrewAI que analisa e decide dataset apropriado
- VisualizaÃ§Ã£o do raciocÃ­nio do agente (transparÃªncia didÃ¡tica)
- Pipeline RAG completo (Retrieval + Augmentation + Generation)
- HistÃ³rico de conversa com visualizaÃ§Ã£o dos logs do agente

Arquitetura (Task 4):
1. AgenticRAGProvider â†’ Roteia query para dataset correto
2. RetrieverProvider â†’ Busca chunks no dataset selecionado
3. AugmentationProvider â†’ Enriquece prompt com chunks
4. GeminiProvider â†’ Gera resposta final
"""

import streamlit as st
import os
import sys
from typing import Dict, Optional

# Adiciona o diretÃ³rio raiz ao path para imports
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from services.agentic_rag_provider import AgenticRAGProvider
from services.retriever_provider import RetrieverProvider
from services.augmentation_provider import AugmentationProvider
from services.gemini_provider import (
    GeminiConfig,
    get_gemini_llm_function,
    validate_gemini_api_key
)


# ==================== CONFIGURAÃ‡ÃƒO DA PÃGINA ====================

st.set_page_config(
    page_title="RAG Agente | Lab Visual",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ¤– LaboratÃ³rio de RAG Agente")
st.markdown("""
Converse com um assistente **inteligente** que roteia automaticamente sua pergunta 
para a base de conhecimento mais apropriada. O agente analisa sua query e decide 
qual dataset usar, tornando o processo **transparente e didÃ¡tico**.
""")

st.divider()


# ==================== INICIALIZAÃ‡ÃƒO DO STATE ====================

def initialize_session_state():
    """Inicializa as variÃ¡veis de estado da sessÃ£o."""
    if "rag_agentic_messages" not in st.session_state:
        st.session_state.rag_agentic_messages = []
    
    if "rag_agentic_logs" not in st.session_state:
        st.session_state.rag_agentic_logs = ""
    
    if "rag_agentic_provider" not in st.session_state:
        st.session_state.rag_agentic_provider = AgenticRAGProvider()
    
    # ConfiguraÃ§Ãµes padrÃ£o do ChromaDB
    if "agentic_chroma_db_path" not in st.session_state:
        st.session_state.agentic_chroma_db_path = "./chroma_db"
    
    if "agentic_chroma_n_results" not in st.session_state:
        st.session_state.agentic_chroma_n_results = 10

initialize_session_state()


# ==================== SIDEBAR - CONFIGURAÃ‡Ã•ES ====================

with st.sidebar:
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    
    # ValidaÃ§Ã£o da API Key do Gemini
    api_key = st.text_input(
        "Gemini API Key",
        type="password",
        value=os.getenv("GEMINI_API_KEY", ""),
        help="Obtenha sua chave em https://ai.google.dev/"
    )
    
    api_key_valid = validate_gemini_api_key(api_key)
    
    if api_key_valid:
        st.success("âœ… API Key vÃ¡lida")
    else:
        st.error("âŒ API Key invÃ¡lida ou nÃ£o fornecida")
    
    st.divider()
    
    # ConfiguraÃ§Ãµes do ChromaDB
    st.subheader("ğŸ—„ï¸ ConfiguraÃ§Ã£o do ChromaDB")
    
    st.session_state.agentic_chroma_db_path = st.text_input(
        "Caminho do Banco",
        value=st.session_state.agentic_chroma_db_path,
        help="Caminho para o diretÃ³rio do ChromaDB persistente"
    )
    
    st.session_state.agentic_chroma_n_results = st.slider(
        "NÃºmero de Chunks",
        min_value=1,
        max_value=20,
        value=st.session_state.agentic_chroma_n_results,
        help="Quantidade de chunks a recuperar por consulta"
    )
    
    st.divider()
    
    # BotÃ£o para limpar histÃ³rico
    if st.button("ğŸ—‘ï¸ Limpar Conversa", use_container_width=True):
        st.session_state.rag_agentic_messages = []
        st.session_state.rag_agentic_logs = ""
        st.success("Conversa limpa com sucesso!")
        st.rerun()
    
    st.divider()
    
    # InformaÃ§Ãµes sobre o Agente
    st.subheader("â„¹ï¸ Sobre o Agente")
    st.info("""
    **CrewAI**: Framework para construir agentes IA colaborativos.
    
    **Roteamento AutomÃ¡tico**: O agente analisa sua query e escolhe:
    - `synthetic_dataset_papers` para perguntas sobre datasets sintÃ©ticos
    - `direito_constitucional` para perguntas sobre direito
    
    **TransparÃªncia**: VocÃª vÃª o raciocÃ­nio do agente ao lado.
    """)


# ==================== FUNÃ‡ÃƒO AUXILIAR - PIPELINE AGENTE RAG ====================

def build_agentic_rag_pipeline(query: str, api_key: str) -> tuple[str, Dict, str]:
    """
    Pipeline Agentic RAG que roteia queries para datasets apropriados.
    
    Fluxo:
    1. AgenticRAGProvider â†’ Roteia query para dataset correto via CrewAI
    2. RetrieverProvider â†’ Busca chunks no dataset selecionado
    3. AugmentationProvider â†’ Enriquece prompt com chunks
    4. Generation â†’ LLM gera resposta final
    
    Args:
        query: Pergunta do usuÃ¡rio
        api_key: Chave da API Gemini
        
    Returns:
        Uma tupla contendo (resposta, routing_result, agent_reasoning)
    """
    agent_reasoning = ""
    routing_result = {}
    
    try:
        # ===== ETAPA 1: AGENTIC ROUTING =====
        print(f"\nğŸ¤– [AGENTIC ROUTING] Analisando query para rotear dataset...")
        
        # Executar roteamento (os logs jÃ¡ vÃ£o para o terminal via TeeOutput no provider)
        routing_result = st.session_state.rag_agentic_provider.route_query(query)
        
        # Obter logs capturados do provider
        agent_reasoning = st.session_state.rag_agentic_provider.last_logs
        
        if not routing_result:
            return "âŒ Erro: O agente nÃ£o conseguiu rotear a query.", {}, agent_reasoning
        
        dataset_name = routing_result.get("dataset_name")
        locale = routing_result.get("locale")
        translated_query = routing_result.get("query", query)
        
        print(f"âœ… [AGENTIC ROUTING] Dataset selecionado: {dataset_name}")
        print(f"   â””â”€ Locale: {locale}")
        print(f"   â””â”€ Query traduzida: {translated_query}")
        
        # ===== ETAPA 2: RETRIEVAL =====
        print(f"\nğŸ” [RETRIEVAL] Buscando chunks em '{dataset_name}'...")
        
        retriever = RetrieverProvider(
            db_path=st.session_state.agentic_chroma_db_path,
            collection_name=dataset_name
        )
        
        chunks = retriever.search(
            query_text=translated_query,
            n_results=st.session_state.agentic_chroma_n_results
        )
        
        if not chunks:
            st.warning(f"""
            âš ï¸ Nenhum chunk recuperado de '{dataset_name}'. 
            Verifique se a coleÃ§Ã£o existe e contÃ©m documentos.
            """)
            chunks = [f"InformaÃ§Ã£o padrÃ£o sobre {dataset_name}"]
        
        print(f"âœ… [RETRIEVAL] Encontrados {len(chunks)} chunks")
        
        # ===== ETAPA 3: AUGMENTATION =====
        print(f"\nğŸ“ [AUGMENTATION] Enriquecendo prompt com chunks...")
        
        augmenter = AugmentationProvider(talk_id="agentic_session")
        prompt = augmenter.generate_prompt(query=translated_query, chunks=chunks)
        
        print(f"âœ… [AUGMENTATION] Prompt gerado ({len(prompt)} caracteres)")
        
        # ===== ETAPA 4: GENERATION =====
        print(f"\nğŸ¤– [GENERATION] Gerando resposta com Gemini...")
        
        llm_config = GeminiConfig(api_key=api_key, temperature=0.7, max_tokens=2000)
        llm_function = get_gemini_llm_function(llm_config)
        
        response = llm_function(prompt)
        
        print(f"âœ… [GENERATION] Resposta gerada ({len(response)} caracteres)")
        
        return response, routing_result, agent_reasoning
        
    except Exception as e:
        error_msg = str(e)
        print(f"âŒ Erro no pipeline: {error_msg}")
        
        if "does not exist" in error_msg:
            return f"""
âŒ **Erro de ConfiguraÃ§Ã£o do ChromaDB**

A coleÃ§Ã£o nÃ£o foi encontrada no caminho configurado.

**PossÃ­veis soluÃ§Ãµes**:
1. Verifique se o caminho estÃ¡ correto
2. Verifique se a coleÃ§Ã£o foi criada
3. Tente usar o caminho absoluto

**Dataset esperado**: {routing_result.get('dataset_name', 'desconhecido')}
**Caminho configurado**: {st.session_state.agentic_chroma_db_path}
            """, routing_result, agent_reasoning
        else:
            return f"âŒ Erro: {error_msg}", routing_result, agent_reasoning


# ==================== INTERFACE DE CHAT ====================

# Exibe o histÃ³rico de mensagens
if st.session_state.rag_agentic_messages:
    for message in st.session_state.rag_agentic_messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
else:
    st.info("ğŸ‘‹ OlÃ¡! Sou um assistente agente de RAG. Qual Ã© sua dÃºvida?")

# Input de chat
if user_query := st.chat_input("Digite sua pergunta..."):
    # Verifica se a API key Ã© vÃ¡lida
    if not api_key_valid:
        st.error("âš ï¸ Por favor, configure uma API Key vÃ¡lida na barra lateral.")
    else:
        # Exibe a mensagem do usuÃ¡rio
        with st.chat_message("user"):
            st.markdown(user_query)
        
        # Adiciona ao histÃ³rico
        st.session_state.rag_agentic_messages.append({
            "role": "user",
            "content": user_query
        })
        
        # Gera a resposta usando o pipeline agentic RAG
        with st.chat_message("assistant"):
            with st.spinner("Analisando e roteando sua pergunta..."):
                response, routing_info, agent_logs = build_agentic_rag_pipeline(
                    query=user_query,
                    api_key=api_key
                )
                
                # Exibe a resposta principal
                st.markdown(response)
                
                # Exibe informaÃ§Ãµes do roteamento
                if routing_info:
                    col1, col2 = st.columns(2)
                    with col1:
                        with st.expander("ğŸ“Š InformaÃ§Ãµes do Roteamento"):
                            st.json(routing_info)
                    
                    with col2:
                        with st.expander("ğŸ§  RaciocÃ­nio do Agente"):
                            st.code(agent_logs, language="text")
        
        # Adiciona resposta ao histÃ³rico
        st.session_state.rag_agentic_messages.append({
            "role": "assistant",
            "content": response
        })
        
        # Rerun para atualizar a interface
        st.rerun()


# ==================== FOOTER ====================

st.divider()

with st.expander("ğŸ” Ver InformaÃ§Ãµes TÃ©cnicas - Pipeline Agentic RAG"):
    st.markdown("""
    ### Arquitetura Agentic RAG
    
    O diferencial desta abordagem Ã© o **roteamento inteligente**:
    
    #### Componentes
    
    1. **AgenticRAGProvider**: Agent CrewAI que roteia queries
       - Analisa a intenÃ§Ã£o do usuÃ¡rio
       - Consulta lista de datasets disponÃ­veis
       - Seleciona o mais apropriado
       - **Retorna**: `{dataset_name, locale, translated_query}`
    
    2. **RetrieverProvider**: Busca no dataset selecionado
       - Usa embeddings semÃ¢nticos
       - Recupera chunks mais relevantes
    
    3. **AugmentationProvider**: Enriquecimento de prompt
       - Combina chunks + contexto
       - Gera prompt otimizado para LLM
    
    4. **GeminiProvider**: GeraÃ§Ã£o de resposta
       - LLM processa prompt enriquecido
       - Retorna resposta contextualizada
    
    #### Fluxo Completo
    
    ```
    Pergunta do UsuÃ¡rio
         â†“
    ğŸ¤– AgenticRAGProvider.route_query()
         â”œâ”€ Analisa intent da query
         â”œâ”€ Consulta datasets disponÃ­veis
         â””â”€ Seleciona dataset correto
         â†“
    ğŸ” RetrieverProvider.search()
         â”œâ”€ Busca em dataset selecionado
         â””â”€ Retorna chunks relevantes
         â†“
    ğŸ“ AugmentationProvider.generate_prompt()
         â”œâ”€ Combina chunks + contexto
         â””â”€ Cria prompt otimizado
         â†“
    ğŸ¤– GeminiProvider.generate()
         â”œâ”€ LLM processa prompt
         â””â”€ Retorna resposta final
         â†“
    Resposta ao UsuÃ¡rio
    ```
    
    #### Vantagens do Roteamento Agente
    
    - âœ… **InteligÃªncia**: Agent aprende padrÃµes de queries
    - âœ… **Escalabilidade**: FÃ¡cil adicionar novos datasets
    - âœ… **PrecisÃ£o**: Dataset certo = respostas mais acuradas
    - âœ… **TransparÃªncia**: RaciocÃ­nio do agente Ã© visÃ­vel
    - âœ… **DidÃ¡tico**: Perfeito para ensinar RAG avanÃ§ado
    
    #### Datasets DisponÃ­veis
    
    | Dataset | Locale | DescriÃ§Ã£o |
    |---------|--------|-----------|
    | `synthetic_dataset_papers` | `en` | Sobre datasets sintÃ©ticos e IA |
    | `direito_constitucional` | `pt-br` | Direito, leis e jurisprudÃªncia |
    
    #### Exemplo de Uso
    
    **Query**: "O que Ã© abandono afetivo no direito constitucional?"
    
    **Roteamento do Agent**:
    ```json
    {
      "dataset_name": "direito_constitucional",
      "locale": "pt-br",
      "query": "O que Ã© direito constitucional fala do abandono afetivo?"
    }
    ```
    
    **Pipeline**: Busca em `direito_constitucional` â†’ Retorna chunks jurÃ­dicos â†’ LLM gera resposta especializada
    """)